各位同事大家好，我是Tywin，在Abacus项目主要做EDA 平台相关工作，所以跟Confluenct Kafka接触比较多。在今年我们把事件平台由Ali RocketMQ切换到
CFK之后，我们跟其他Abacus 应用组的同事也属于第一批尝鲜的用户。在sit及pre-uat过程中，我们遇到了一些Producer，consumer及CFK平台相关问题，在Ali及Confluent团队的协助下，
我们也算是踩过了这些问题，今天借着这个机会跟大家分享一下，如果各位有更好的想法或者建议，欢迎随时沟通与交流。

在此之前，我想先分享一下我们在使用不同message queue的一些体验，如果提到一些问题，不一定是产品自身的问题，可能是我作为用户打开方式不太对。在消息队列，我属于新手，最开始接触的GoogleCloud的
Pub/Sub，叫他消息队列，等效我们熟知的rocektmq跟kafka， 我们利用pub/sub + dataflow做了一个准实时的消息处理系统，dataflow是一个全托管的云上流式处理平台， 可以Flink。PubSub负责承载消息，Dataflow处理消息，处理包括过滤，转换，转发。使用及开发过程比较丝滑，
对于pub/sub，我们的最基本的需求是收发消息，可以按topic，订阅划分不同权限，这些它能支持，我们发现在使用过程中最好把消息落库去方便查询及排查问题，然后先想到了Dataflow，一个很简单的Dataflow job就可以做到这一点，但dataflow job做这种事大材小用了费用也比较高，在后来发现pub/sub可以支持BigQuery订阅，这个订阅可以直接把消息写入BigQuery数据库。没有额外费用，也非常稳定。作为一个企业级项目，监控也是必不可少的，利用Google Cloud原生提供的监控能力，我们可以监控实时TPS，平均消息大小，尤其要说明的是，它可以监控最老未确认的消息时长以及没有确认的消息数量。 还可以根据任意指标来设置告警规则。听着可能是平平无奇的指标，但对业务告警非常方便， 实时TPS我们可以设置一个流量告警，在流量低于一定值时告警，最老未确认的消息时长可以设置如果消费者超过多长时间未处理消息就触发警告，未确认的消息数相当于我们现在经常说的消息积压数，也是非常重要的告警指标。 另外要提到Dataflow，我们使用也非常丝滑，开发非常好用，开发过程就像在流水线组装零件，整个平台非常稳定，我们系统运行两年以上没有发现Dataflow自身服务异常造成的问题。 另外值得一提的我们上线后的FF很少，在很长时间内几乎没有告警，为数不多的几次告警都是上游或者下游停机维护。非常稳定。

就在我们习惯了这两种组合，后续要做AlirocketMQ时我们先考虑到的是消息处理的好搭档对标dataflow的Flink，因为一些原因Flink在行内阿里云还不能使用，相当于缺失了很重要的一部分。我们转战神马产品SmartEDA去处理实时消息，今天主要分享消息队列相关，因此主要探讨AliRocketMQ，我们拿着pub/sub的习惯去看Alirocketmq，AliRockeTMQ在我们开发及使用过程中容易易上手，在业务处理过程中几乎没有遇到过AliRocketMQ自身的问题，经常会有同事找过来说帮忙看一下Ali RockeTMQ是不是出问题了，但基本上都是业务代码或着业务处理有问题。其实在最开始我们也有看之前在pub/sub觉得顺理成章的几个点1. 权限分配 2.监控 3. 消息落库  AliRocketMQ（当前版本）的权限分配是instance level，不能按topic跟订阅分配 2. 阿里也提供了很多监控指标，但没有最老未确认的消息时长，有消息积压指标，但无数据 3. 消息落库，习惯性的去找Alirocketmq有没有类似bigquery订阅可以有个Maxcomputer订阅可以直接把消息落在MAxComputer或者其它数据库，也不支持。 总之在最后我们适应了ali rocketmq的使用方式，也支持了相当长时间的业务处理，没有发现重大问题。

下来到今天的主题CFK，Confluent Kafka虽然之前没听说过，但Kafka早已久仰大名，而且用户非常多，我们满怀期待。我们带着RocketMQ的习惯去看Kafka，从开发上就开始不适应。
1. 最重要的一点，消费者消息重试及确认机制，rocketmq可以一条一条确认消息，并且支持消息自动重试，未确认或者确认失败的消息默认支持退避策略重推16次。到了CFK，没了，需要自己开发重试机制，消息也不能一条一条确认。这个对于用户非常重要，我们也给CFK专家反馈过多次，目前CFK功能层面没法支持，需要应用处理。  （特别这一点，让我们体验到了自动挡突然变手动挡的感觉）
2.好消息是CFK可以按topic，group划分权限
3.如果要把消息直接通过类似bigquery订阅的形式写入表也需要借助工具开发或者原生开发，最起码也得单独有个平台去部署运行。
4.有办法或者有工具监控消费组积压情况，但需要CTO team去集成，目前还在沟通当中。
5.平台稳定性，迁到CFK后遇到过一次服务不可用的情况，后来确认是我们部署在开发场的ack集群人为操作导致的问题，是基础设施不可用了，不是CFK自身问题。好消息是CTO team UAT的CFK目前还未发生过服务不可用的情况。

现在，站在目前这个时间节点，我们趟过了这些路，也适应了CFK，以下是我们在CFK中遇到的问题以及CFK推荐的解决方案。


优化一下这个讲稿


ChatGPT 说：
各位同事，大家好！我是Tywin，主要负责Abacus项目的EDA平台工作，与Confluent Kafka（CFK）的对接较多。今年，我们率先将事件平台从阿里RocketMQ切换到了CFK，在 SIT 和 Pre-UAT 阶段，遇到了一些生产者、消费者及平台层面的问题。在阿里和 Confluent 团队的大力支持下，这些问题都已得到解决。今天借此机会，跟大家分享我们的经验和心得，也欢迎各位提出宝贵建议。

一、不同消息队列的使用体验
1. Google Cloud Pub/Sub + Dataflow
架构：Pub/Sub 负责消息承载；Dataflow（Flink）负责过滤、转换、转发。

优点：

消息持久化：最初通过 Dataflow 作持久化，后改为 BigQuery 订阅，省时省钱且稳定。

监控与告警：可实时监控 TPS、最老未确认消息时长、未确认消息数等关键指标；并能基于任意指标灵活设定告警。

稳定性：两年多来极少告警，几次异常都是上下游系统维护所致。

2. 阿里 RocketMQ + SmartEDA
背景：原计划引入 Flink 无奈行内阿里云暂不支持，因而使用 SmartEDA 处理实时流。

RocketMQ 体验：

开发及运行中几乎未碰到平台自身缺陷，绝大多数问题源于业务代码。

权限管理为 Instance 级别，不可精细到 Topic/Group；监控缺少“最老未确认消息时长”指标；无原生落库订阅。

适应与总结：经过调试和业务适配，长时间运行稳定，未出现重大故障。

二、Confluent Kafka（CFK）初体验
我们怀着对 Kafka 的美好期望入场，但也遇到以下“从自动挡切手动挡”的挑战：

消息确认与重试

RocketMQ 可逐条确认，并内置背off 重试（16 次）；CFK 则需在应用层自行实现重试逻辑，且无法逐条 ACK。

权限管理

CFK 支持按 Topic 与 Group 精细划分权限。

消息落库

无原生类似 BigQuery 订阅功能，需要额外开发或借助外部平台。

消费积压监控

可通过 CTO 团队已有工具集成，但仍在部署对接中。

平台稳定性

迁移后唯一一次不可用事件，源于我们自建 ACK 集群的误操作；Confluent 官方 UAT 环境至今未出现过可用性问题。

三、CFK 问题与推荐方案
问题	推荐解决方案
1. 应用层重试与确认	利用 Kafka Consumer Interceptor 或开发统一中间件，实现幂等消费和退避重试；并借助事务 API 保证消息处理精确一次。
2. 消息落库	采用 Kafka Connect，使用 JDBC Sink 或专用 Connector 将消息持久化到目标数据库。
3. 消费端积压监控	部署 Confluent Control Center 或第三方监控（Prometheus + Grafana），并配置 lag 报警。
4. 运行稳定性	建议开启多可用区部署、监控 Broker 健康状况，利用 Cruise Control 做自动扩缩容和负载均衡。

四、总结与展望
适配与升级：从 RocketMQ 到 CFK，需要调整的主要是消费确认和运维监控层面，业务逻辑重试策略必须上移到应用层。

工具链完善：借助 Kafka Connect、Control Center、Prometheus/Grafana 等，构建成熟的生态。

社区与支持：Confluent 官方和开源社区资源丰富，建议多关注新特性与最佳实践，持续优化平台能力。

以上就是我们的分享，欢迎大家随时交流讨论！谢谢！
